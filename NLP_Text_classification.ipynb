{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***In this file, we only focus on the model with 1 and 2 features; and using 6 main method to evaluate then compare them!***\n",
    "\n",
    "First, I have to note something about this part.\n",
    "\n",
    "1) In `XGBoost, AdaBoost` we fixed, (and) pick the `learning_rate` = 0.1.\n",
    "\n",
    "2) In `XGBoost, AdaBoost` and `Random Forest`; we pick the `n_estimators` = 300.\n",
    "\n",
    "3) In `XGBoost` and `RandomForest`; the `max_depth` = 3\n",
    "\n",
    "4) The study about the affects of the optimal `learning_rate, n_estimator` and `max_depth` will be considered in the next Session!\n",
    "\n",
    "5) The 3 last methodologies are `Naive Bayes, Logistic Regression & KNN`\n",
    "\n",
    "Now, we need import the following `libraries`...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv(r\"train.csv\", usecols = [\"text\", \"target\"])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Checking null-values***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['col_names : \\ttext', 'col_names : \\ttarget'], dtype='object')\n",
      "\n",
      "\n",
      "Data-dimensions: \t(7613, 2)\n",
      "\n",
      "\n",
      "Count the not-null values of each features: \n",
      "text      7613\n",
      "target    7613\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"col_names : \\t\" + df.columns)\n",
    "print('\\n')\n",
    "print(\"Data-dimensions: \\t\" + str(df.shape))\n",
    "print('\\n')\n",
    "print(\"Count the not-null values of each features: \\n\" + str(df.notnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Checking & removing duplications***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new dimension after checking duplicate & removing is:\t(7521, 2)\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(inplace = True)\n",
    "print(\"The new dimension after checking duplicate & removing is:\\t\" + str(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Adding variables named Text length & Number of words to get the new model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>Text_length</th>\n",
       "      <th>Numb_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  Text_length  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1           69   \n",
       "1             Forest fire near La Ronge Sask. Canada       1           38   \n",
       "2  All residents asked to 'shelter in place' are ...       1          133   \n",
       "3  13,000 people receive #wildfires evacuation or...       1           65   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1           88   \n",
       "\n",
       "   Numb_words  \n",
       "0          13  \n",
       "1           7  \n",
       "2          22  \n",
       "3           8  \n",
       "4          16  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text_length'] = df['text'].str.len()\n",
    "df['Numb_words'] = df['text'].str.split().map(lambda x: len(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Define 2 classes: Text_Selector for text-column and Number_Selector for the 2 new features***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, field):\n",
    "        self.field = field\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.field]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, field):\n",
    "        self.field = field\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[[self.field]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Define a `Tokenizer`  function***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from spellchecker import SpellChecker    \n",
    "\n",
    "def Tokenizer(str_input):\n",
    "    ## 1. Remove url_link\n",
    "    remove_url = re.compile(r'https?://\\S+|www\\.\\S+').sub(r'', str_input)\n",
    "    \n",
    "    ## 2. Remove html_link\n",
    "    remove_html = re.compile(r'<.*?>').sub(r'', remove_url)\n",
    "    \n",
    "    ## 3. Remove Emojis\n",
    "    remove_emo = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE).sub(r'', remove_html)\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", remove_emo).lower().split()    \n",
    "        \n",
    "    ## 4. spell_correction\n",
    "    # spell = SpellChecker()\n",
    "    # words = [spell.correction(word) for word in words]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Assign X, y to train_test_split & fit the corresponding model***\n",
    "\n",
    "`We only consider 2 case: ('text' & 'numb_words') and ('text' & 'text_length')`\n",
    "\n",
    "\n",
    "***`1) Case1. Data contains 'text' & 'numb_words'`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['text', 'Numb_words']] \n",
    "y = df['target']\n",
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split dataset into 2 parts: train & test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = test_size, \n",
    "                                                    stratify = y, \n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import some libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1. Using AdaBoost_classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier1 = Pipeline([\n",
    "    (\n",
    "        'features', FeatureUnion([\n",
    "        ('text', Pipeline([\n",
    "            ('colext', TextSelector('text')),\n",
    "            ('tfidf', TfidfVectorizer(tokenizer = Tokenizer, stop_words = 'english',\n",
    "                     min_df = .0025, max_df = 0.25, ngram_range = (1, 3) ) ),\n",
    "            ('svd', TruncatedSVD(algorithm = 'randomized', n_components = 300) ), #for AdaBoost\n",
    "        ])),\n",
    "        ('words', Pipeline([\n",
    "            ('wordext', NumberSelector('Numb_words')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),            \n",
    "    ])\n",
    "    ),\n",
    "    ('clf', AdaBoostClassifier(n_estimators = 300, learning_rate = 0.1)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit&trainning time :  63.551987171173096\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "classifier1.fit(X_train, y_train)\n",
    "preds = classifier1.predict(X_test)\n",
    "\n",
    "print ('Fit&trainning time : ', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict & accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 77.53%\n",
      "Testing Accuracy: 74.08%\n",
      "Precision: 0.7759882869692533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.88      0.80      1295\n",
      "           1       0.78      0.55      0.64       962\n",
      "\n",
      "    accuracy                           0.74      2257\n",
      "   macro avg       0.75      0.72      0.72      2257\n",
      "weighted avg       0.75      0.74      0.73      2257\n",
      "\n",
      "[[1142  153]\n",
      " [ 432  530]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix\n",
    "\n",
    "train_acc_Ada = accuracy_score(y_train, classifier1.predict(X_train)) * 100.0 \n",
    "test_acc_Ada = accuracy_score(y_test, preds) * 100\n",
    "\n",
    "print(\"Training Accuracy: %.2f%%\" % train_acc_Ada)\n",
    "print(\"Testing Accuracy: %.2f%%\" % test_acc_Ada)\n",
    "print(\"Precision:\", precision_score(y_test, preds))\n",
    "print(classification_report(y_test, preds))\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2. Using XGBoost_classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit&trainning time :  47.76820182800293\n",
      "Training_Accuracy: 90.16%\n",
      "Testing_Accuracy: 77.18%\n",
      "Precision: 0.7776397515527951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.86      0.81      1295\n",
      "           1       0.78      0.65      0.71       962\n",
      "\n",
      "    accuracy                           0.77      2257\n",
      "   macro avg       0.77      0.76      0.76      2257\n",
      "weighted avg       0.77      0.77      0.77      2257\n",
      "\n",
      "[[1116  179]\n",
      " [ 336  626]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(probability = True, kernel = 'linear')\n",
    "\n",
    "from xgboost import XGBClassifier \n",
    "classifier1 = Pipeline([\n",
    "    (\n",
    "        'features', FeatureUnion([\n",
    "        ('text', Pipeline([\n",
    "            ('colext', TextSelector('text')),\n",
    "            ('tfidf', TfidfVectorizer(tokenizer = Tokenizer, stop_words = 'english',\n",
    "                     min_df = .0025, max_df = 0.25, ngram_range = (1, 3) ) ),\n",
    "            ('svd', TruncatedSVD(algorithm ='randomized', n_components = 300) ), #for XGB\n",
    "        ])),\n",
    "        ('words', Pipeline([\n",
    "            ('wordext', NumberSelector('Numb_words')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),            \n",
    "    ])\n",
    "    ),\n",
    "    ('clf', XGBClassifier(max_depth = 3, n_estimators = 300, base_estimator = svc, learning_rate = 0.1))\n",
    "    ])\n",
    "\n",
    "## Fit the model\n",
    "start = time.time()\n",
    "classifier1.fit(X_train, y_train)\n",
    "preds = classifier1.predict(X_test)\n",
    "print ('Fit&trainning time : ', time.time() - start)\n",
    "\n",
    "train_acc_Xgb = accuracy_score(y_train, classifier1.predict(X_train)) * 100.0 \n",
    "test_acc_Xgb = accuracy_score(y_test, preds) * 100.0\n",
    "\n",
    "print(\"Training_Accuracy: %.2f%%\" % train_acc_Xgb)\n",
    "print(\"Testing_Accuracy: %.2f%%\" % test_acc_Xgb)\n",
    "print(\"Precision:\", precision_score(y_test, preds))\n",
    "print(classification_report(y_test, preds))\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3. Using RandomForest_classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit&trainning time :  7.6379077434539795\n",
      "Training_Accuracy: 71.60%\n",
      "Testing_Accuracy: 69.78%\n",
      "Precision: 0.8398058252427184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.95      0.78      1295\n",
      "           1       0.84      0.36      0.50       962\n",
      "\n",
      "    accuracy                           0.70      2257\n",
      "   macro avg       0.75      0.65      0.64      2257\n",
      "weighted avg       0.74      0.70      0.66      2257\n",
      "\n",
      "[[1229   66]\n",
      " [ 616  346]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier1 = Pipeline([\n",
    "    (\n",
    "        'features', FeatureUnion([\n",
    "        ('text', Pipeline([\n",
    "            ('colext', TextSelector('text')),\n",
    "            ('tfidf', TfidfVectorizer(tokenizer = Tokenizer, stop_words = 'english',\n",
    "                     min_df = .0025, max_df = 0.25, ngram_range = (1, 3) ) ),\n",
    "            ('svd', TruncatedSVD(algorithm ='randomized', n_components = 300) ), \n",
    "        ])),\n",
    "        ('words', Pipeline([\n",
    "            ('wordext', NumberSelector('Numb_words')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),            \n",
    "    ])\n",
    "    ),\n",
    "    ('clf', RandomForestClassifier(max_depth = 3, n_estimators = 300)),\n",
    "    ])\n",
    "\n",
    "start = time.time()\n",
    "classifier1.fit(X_train, y_train)\n",
    "preds = classifier1.predict(X_test)\n",
    "print ('Fit&trainning time : ', time.time() - start)\n",
    "\n",
    "train_acc_RFC = accuracy_score(y_train, classifier1.predict(X_train)) * 100.0\n",
    "test_acc_RFC = accuracy_score(y_test, preds) * 100.0\n",
    "\n",
    "print(\"Training_Accuracy: %.2f%%\" % train_acc_RFC )\n",
    "print(\"Testing_Accuracy: %.2f%%\" % test_acc_RFC )\n",
    "print(\"Precision:\", precision_score(y_test, preds))\n",
    "print(classification_report(y_test, preds))\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4. Using NaiveBayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Accuracy: 90.44%\n",
      "Testing_Accuracy: 79.26%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83      1295\n",
      "           1       0.78      0.71      0.74       962\n",
      "\n",
      "    accuracy                           0.79      2257\n",
      "   macro avg       0.79      0.78      0.78      2257\n",
      "weighted avg       0.79      0.79      0.79      2257\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1108  187]\n",
      " [ 281  681]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "text_process = CountVectorizer(analyzer = Tokenizer).fit_transform(df['text'])\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_process, df['target'], \n",
    "                                                    test_size = test_size, \n",
    "                                                    stratify = df['target'], \n",
    "                                                    random_state = 42)\n",
    "\n",
    "classifier1 = MultinomialNB()\n",
    "classifier1.fit(X_train, y_train)\n",
    "preds = classifier1.predict(X_test)\n",
    "\n",
    "train_acc_NVB = accuracy_score(y_train, classifier1.predict(X_train)) * 100.0\n",
    "test_acc_NVB = accuracy_score(y_test, preds) * 100.0\n",
    "\n",
    "print(\"Training_Accuracy: %.2f%%\" % train_acc_NVB)\n",
    "print(\"Testing_Accuracy: %.2f%%\" % test_acc_NVB)\n",
    "print(classification_report(y_test, preds))\n",
    "print('Confusion Matrix: \\n',confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5) Using Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Accuracy: 78.38%\n",
      "Testing_Accuracy: 76.92%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.81      1295\n",
      "           1       0.80      0.62      0.69       962\n",
      "\n",
      "    accuracy                           0.77      2257\n",
      "   macro avg       0.78      0.75      0.75      2257\n",
      "weighted avg       0.77      0.77      0.76      2257\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1143  152]\n",
      " [ 369  593]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['target'], \n",
    "                                                    stratify = df['target'],\n",
    "                                                    test_size = test_size, \n",
    "                                                    random_state = 42)\n",
    "\n",
    "\n",
    "# Initialize the tfidf_vectorizer \n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words = 'english', max_df = 0.7) \n",
    "\n",
    "# Fit and transform the training data to Tfidf_Vec\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Fit the model\n",
    "C = 0.1\n",
    "classifier1 = LogisticRegression(random_state = 42, C = C).fit(tfidf_train, y_train)\n",
    "\n",
    "preds = classifier1.predict(tfidf_test)\n",
    "\n",
    "train_acc_logreg = accuracy_score(y_train, classifier1.predict(tfidf_train)) * 100.0\n",
    "test_acc_logreg = accuracy_score(y_test, preds) * 100.0\n",
    "\n",
    "print(\"Training_Accuracy: %.2f%%\" % train_acc_logreg)\n",
    "print(\"Testing_Accuracy: %.2f%%\" % test_acc_logreg)\n",
    "print(classification_report(y_test, preds))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6) Using KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Accuracy: 78.38%\n",
      "Testing_Accuracy: 76.92%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.81      1295\n",
      "           1       0.80      0.62      0.69       962\n",
      "\n",
      "    accuracy                           0.77      2257\n",
      "   macro avg       0.78      0.75      0.75      2257\n",
      "weighted avg       0.77      0.77      0.76      2257\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1143  152]\n",
      " [ 369  593]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 100)\n",
    "classifier1 = knn.fit(tfidf_train, y_train)\n",
    "\n",
    "preds = knn.predict(tfidf_test)\n",
    "\n",
    "train_acc_knn = accuracy_score(y_train, knn.predict(tfidf_train)) * 100.0\n",
    "test_acc_knn = accuracy_score(y_test, preds) * 100.0\n",
    "\n",
    "print(\"Training_Accuracy: %.2f%%\" % train_acc_knn)\n",
    "print(\"Testing_Accuracy: %.2f%%\" % test_acc_knn)\n",
    "print(classification_report(y_test, preds))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary 1.** With the model contains 2 features `'text'` and `'number of words'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc(%)</th>\n",
       "      <th>test_acc(%)</th>\n",
       "      <th>used_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>77.526596</td>\n",
       "      <td>74.080638</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>90.159574</td>\n",
       "      <td>77.182100</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>71.599544</td>\n",
       "      <td>69.782898</td>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>90.444529</td>\n",
       "      <td>79.264510</td>\n",
       "      <td>Naive_Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>71.143617</td>\n",
       "      <td>70.934869</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>78.381459</td>\n",
       "      <td>76.916261</td>\n",
       "      <td>k-NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_acc(%)  test_acc(%)          used_method\n",
       "0     77.526596    74.080638             AdaBoost\n",
       "1     90.159574    77.182100              XGBoost\n",
       "2     71.599544    69.782898         RandomForest\n",
       "3     90.444529    79.264510          Naive_Bayes\n",
       "4     71.143617    70.934869  Logistic_Regression\n",
       "5     78.381459    76.916261                 k-NN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc = [train_acc_Ada, train_acc_Xgb, train_acc_RFC, train_acc_NVB, train_acc_logreg, train_acc_knn]\n",
    "test_acc = [test_acc_Ada, test_acc_Xgb, test_acc_RFC, test_acc_NVB, test_acc_logreg, test_acc_knn]\n",
    "method = ['AdaBoost', 'XGBoost', 'RandomForest', 'Naive_Bayes', 'Logistic_Regression', 'k-NN']\n",
    "\n",
    "model1 = pd.DataFrame({'train_acc(%)': train_acc,\n",
    "                       'test_acc(%)' : test_acc,\n",
    "                       'used_method': method})\n",
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`2) Case2. Data contains 'text' & 'text_length'`**\n",
    "\n",
    "`So the first step in this case is assign X, y again to the new columns_names`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['text', 'Text_length']] \n",
    "y = df['target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.20, \n",
    "                                                    stratify = y, \n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1. AdaBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit&trainning time :  69.14977693557739\n",
      "Training_Accuracy: 69.65%\n",
      "Testing_Accuracy: 68.50%\n",
      "Precision: 0.71875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.87      0.76       863\n",
      "           1       0.72      0.43      0.54       642\n",
      "\n",
      "    accuracy                           0.69      1505\n",
      "   macro avg       0.70      0.65      0.65      1505\n",
      "weighted avg       0.69      0.69      0.67      1505\n",
      "\n",
      "[[755 108]\n",
      " [366 276]]\n"
     ]
    }
   ],
   "source": [
    "classifier2 = Pipeline([\n",
    "    (\n",
    "        'features', FeatureUnion([\n",
    "        ('text', Pipeline([\n",
    "            ('colext', TextSelector('text')),\n",
    "            ('tfidf', TfidfVectorizer(tokenizer = Tokenizer, stop_words = 'english',\n",
    "                     min_df = .0025, max_df = 0.25, ngram_range = (1, 3) ) ),\n",
    "            ('svd', TruncatedSVD(algorithm ='randomized', n_components = 300) ), \n",
    "        ])),\n",
    "        ('words', Pipeline([\n",
    "            ('wordext', NumberSelector('Text_length')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),            \n",
    "    ])\n",
    "    ),\n",
    "    ('clf', AdaBoostClassifier(n_estimators = 300, learning_rate = 0.01)),\n",
    "    ])\n",
    "\n",
    "start = time.time()\n",
    "classifier2.fit(X_train, y_train)\n",
    "preds = classifier2.predict(X_test)\n",
    "print('Fit&trainning time : ', time.time() - start)\n",
    "\n",
    "train_acc_Ada2 = accuracy_score(y_train, classifier2.predict(X_train)) * 100.0\n",
    "test_acc_Ada2 = accuracy_score(y_test, preds) * 100.0\n",
    "\n",
    "print(\"Training_Accuracy: %.2f%%\" % train_acc_Ada2)\n",
    "print(\"Testing_Accuracy: %.2f%%\" % test_acc_Ada2)\n",
    "print(\"Precision:\", precision_score(y_test, preds))\n",
    "print(classification_report(y_test, preds))\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2. XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit&trainning time :  52.975799798965454\n",
      "Training_Accuracy: 88.78%\n",
      "Testing_Accuracy: 78.41%\n",
      "Precision: 0.7887067395264117\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82       863\n",
      "           1       0.79      0.67      0.73       642\n",
      "\n",
      "    accuracy                           0.78      1505\n",
      "   macro avg       0.79      0.77      0.77      1505\n",
      "weighted avg       0.78      0.78      0.78      1505\n",
      "\n",
      "[[747 116]\n",
      " [209 433]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(probability = True, kernel = 'linear')\n",
    "\n",
    "from xgboost import XGBClassifier \n",
    "classifier2 = Pipeline([\n",
    "    (\n",
    "        'features', FeatureUnion([\n",
    "        ('text', Pipeline([\n",
    "            ('colext', TextSelector('text')),\n",
    "            ('tfidf', TfidfVectorizer(tokenizer = Tokenizer, stop_words = 'english',\n",
    "                     min_df = .0025, max_df = 0.25, ngram_range = (1, 3) ) ),\n",
    "            ('svd', TruncatedSVD(algorithm ='randomized', n_components = 300) ), #for XGB\n",
    "        ])),\n",
    "        ('words', Pipeline([\n",
    "            ('wordext', NumberSelector('Text_length')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),            \n",
    "    ])\n",
    "    ),\n",
    "    ('clf', XGBClassifier(max_depth = 3, n_estimators = 300, base_estimator = svc, learning_rate = 0.1))\n",
    "    ])\n",
    "\n",
    "## Fit the model\n",
    "start = time.time()\n",
    "classifier2.fit(X_train, y_train)\n",
    "preds = classifier2.predict(X_test)\n",
    "print ('Fit&trainning time : ', time.time() - start)\n",
    "\n",
    "train_acc_Xgb2 = accuracy_score(y_train, classifier2.predict(X_train)) * 100.0 \n",
    "test_acc_Xgb2 = accuracy_score(y_test, preds) * 100.0\n",
    "\n",
    "print(\"Training_Accuracy: %.2f%%\" % train_acc_Xgb2)\n",
    "print(\"Testing_Accuracy: %.2f%%\" % test_acc_Xgb2)\n",
    "print(\"Precision:\", precision_score(y_test, preds))\n",
    "print(classification_report(y_test, preds))\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3. Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit&trainning time :  8.966670274734497\n",
      "Training_Accuracy: 72.41%\n",
      "Testing_Accuracy: 71.30%\n",
      "Precision: 0.828125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.94      0.79       863\n",
      "           1       0.83      0.41      0.55       642\n",
      "\n",
      "    accuracy                           0.71      1505\n",
      "   macro avg       0.75      0.67      0.67      1505\n",
      "weighted avg       0.74      0.71      0.69      1505\n",
      "\n",
      "[[808  55]\n",
      " [377 265]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier2 = Pipeline([\n",
    "    (\n",
    "        'features', FeatureUnion([\n",
    "        ('text', Pipeline([\n",
    "            ('colext', TextSelector('text')),\n",
    "            ('tfidf', TfidfVectorizer(tokenizer = Tokenizer, stop_words = 'english',\n",
    "                     min_df = .0025, max_df = 0.25, ngram_range = (1, 3) ) ),\n",
    "            ('svd', TruncatedSVD(algorithm ='randomized', n_components = 300) ), \n",
    "        ])),\n",
    "        ('words', Pipeline([\n",
    "            ('wordext', NumberSelector('Text_length')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),            \n",
    "    ])\n",
    "    ),\n",
    "    ('clf', RandomForestClassifier(max_depth = 3, n_estimators = 300)),\n",
    "    ])\n",
    "\n",
    "start = time.time()\n",
    "classifier2.fit(X_train, y_train)\n",
    "preds = classifier2.predict(X_test)\n",
    "print ('Fit&trainning time : ', time.time() - start)\n",
    "\n",
    "train_acc_RFC2 = accuracy_score(y_train, classifier2.predict(X_train)) * 100.0\n",
    "test_acc_RFC2 = accuracy_score(y_test, preds) * 100.0\n",
    "\n",
    "print(\"Training_Accuracy: %.2f%%\" % train_acc_RFC2 )\n",
    "print(\"Testing_Accuracy: %.2f%%\" % test_acc_RFC2 )\n",
    "print(\"Precision:\", precision_score(y_test, preds))\n",
    "print(classification_report(y_test, preds))\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noting that in 3 last methods (`NaiveBayes, Logistic Regression & K nearest neighbor`); we only consider only the `'text'` feature and ignored `'numb_words'` also `'text_length'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc(%)</th>\n",
       "      <th>test_acc(%)</th>\n",
       "      <th>used_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>69.647606</td>\n",
       "      <td>68.504983</td>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>88.779920</td>\n",
       "      <td>78.405316</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>72.406915</td>\n",
       "      <td>71.295681</td>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>90.444529</td>\n",
       "      <td>79.264510</td>\n",
       "      <td>Naive_Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>71.143617</td>\n",
       "      <td>70.934869</td>\n",
       "      <td>Logistic_Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>78.381459</td>\n",
       "      <td>76.916261</td>\n",
       "      <td>k-NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_acc(%)  test_acc(%)          used_method\n",
       "0     69.647606    68.504983             AdaBoost\n",
       "1     88.779920    78.405316              XGBoost\n",
       "2     72.406915    71.295681         RandomForest\n",
       "3     90.444529    79.264510          Naive_Bayes\n",
       "4     71.143617    70.934869  Logistic_Regression\n",
       "5     78.381459    76.916261                 k-NN"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc = [train_acc_Ada2, train_acc_Xgb2, train_acc_RFC2, train_acc_NVB, train_acc_logreg, train_acc_knn]\n",
    "test_acc = [test_acc_Ada2, test_acc_Xgb2, test_acc_RFC2, test_acc_NVB, test_acc_logreg, test_acc_knn]\n",
    "method = ['AdaBoost', 'XGBoost', 'RandomForest', 'Naive_Bayes', 'Logistic_Regression', 'k-NN']\n",
    "\n",
    "model2 = pd.DataFrame({'train_acc(%)': train_acc,\n",
    "                       'test_acc(%)' : test_acc,\n",
    "                       'used_method': method})\n",
    "model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
